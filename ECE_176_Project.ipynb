{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446e9a18",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">ECE 176 Project</h1>\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. Dataset Preparation: we will implement an American Sign Language (ASL) alphabet library.\n",
    "2. Model: create a neural network architecture for our dataset.\n",
    "3. Finetuning: find ways to improve the model.\n",
    "4. Test/Visuals: create tests and look at which ASL letters were best recognized and why.\n",
    "5. Conclusion/Discussion: discussion of results and possible further study.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45e6a3",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "https://www.kaggle.com/grassknoted/aslalphabet_akash nagaraj_2018,\n",
    "#### ASL Alphabet\n",
    "https://www.kaggle.com/dsv/29550\n",
    "10.34740/KAGGLE/DSV/29550\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142217cd",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Initially, we will focus on implementing an American Sign Language (ASL) alphabet library. This involves loading the ASL alphabet dataset, a step that may require a few minutes upon the first attempt. Subsequently, the data will be cached, ensuring quicker access in future sessions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5577ca08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# ensure consistency across runs\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d159a",
   "metadata": {},
   "source": [
    "### CustomImageDataset\n",
    "Using the pytorch example and taking inspiration from previous assignment, below is the class created for uploading the training and testing datasets to pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08aa86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None, mode='train'):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.mode = mode\n",
    "        self.img_labels = self._get_image_labels()\n",
    "\n",
    "\n",
    "    def _get_image_labels(self):\n",
    "        img_labels = []\n",
    "        if self.mode == 'train':\n",
    "            label = 0\n",
    "            for root, dirs, files in os.walk(self.img_dir):\n",
    "                for subdir in sorted(dirs):\n",
    "                    subdir_path = os.path.join(root, subdir)\n",
    "                    for _, _, files in os.walk(subdir_path):\n",
    "                        for file in files:\n",
    "                            if file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                                img_labels.append((os.path.join(subdir, file), label))\n",
    "                    label += 1\n",
    "        elif self.mode == 'test':\n",
    "            for root, _, files in os.walk(self.img_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                        img_labels.append((file, None))\n",
    "        return img_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.img_labels[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_path)\n",
    "        image = Image.open(img_path).convert('RGB')  # Use PIL to open image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform and label is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "class CustomImageDatasetSkele(Dataset):\n",
    "    def __init__(self, img_dir, skeleton_dir, transform=None, target_transform=None, mode='train'):\n",
    "        self.img_dir = img_dir\n",
    "        self.skeleton_dir = skeleton_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.mode = mode\n",
    "        self.img_labels = self._get_image_labels()\n",
    "\n",
    "    def _get_image_labels(self):\n",
    "        img_labels = []\n",
    "        if self.mode == 'train':\n",
    "            label = 0\n",
    "            for root, dirs, files in os.walk(self.img_dir):\n",
    "                for subdir in sorted(dirs):\n",
    "                    subdir_path = os.path.join(root, subdir)\n",
    "                    for _, _, files in os.walk(subdir_path):\n",
    "                        for file in files:\n",
    "                            if file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                                img_labels.append((os.path.join(subdir, file), label))\n",
    "                    label += 1\n",
    "        elif self.mode == 'test':\n",
    "            for root, _, files in os.walk(self.img_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                        img_labels.append((file, None))\n",
    "        return img_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.img_labels[idx]\n",
    "        full_img_path = os.path.join(self.img_dir, img_path)\n",
    "        skeleton_path = os.path.join(self.skeleton_dir, img_path)  # Adjust if the structure is different\n",
    "\n",
    "        image = Image.open(full_img_path).convert('RGB')\n",
    "        skeleton = Image.open(skeleton_path).convert('L')\n",
    "        \n",
    "        # Stack the grayscale image as an additional channel to create a 4-channel image\n",
    "        combined_image = Image.merge(\"RGBA\", image.split() + (skeleton,))\n",
    "\n",
    "        if self.transform:\n",
    "            combined_image = self.transform(combined_image)\n",
    "\n",
    "        if self.target_transform and label is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return combined_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d3a87",
   "metadata": {},
   "source": [
    "# Default Training/Test Set\n",
    "\n",
    "Below is a list of the directories used for storing the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06863280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yann or Sebastian? Enter your name as seen hereYann\n",
      "You are currently in Yann s path\n",
      "/home/ybaglinbunod/private/unchanged_train/asl_alphabet_train/asl_alphabet_train\n"
     ]
    }
   ],
   "source": [
    "### User, Yann or Sebastian ###\n",
    "\n",
    "image_size = (200,200)\n",
    "\n",
    "username = input(\"Yann or Sebastian? Enter your name as seen here\")\n",
    "print('You are currently in', username,'s path')\n",
    "\n",
    "if username == 'Yann':\n",
    "    img_directory='/home/ybaglinbunod/private/unchanged_train/asl_alphabet_train/asl_alphabet_train'\n",
    "    img_directory2='/home/ybaglinbunod/private/unchanged_train/asl_alphabet_test/asl_alphabet_test'\n",
    "    img_dir='/home/ybaglinbunod/private/unchanged_test'\n",
    "    img_skeleton='/home/ybaglinbunod/private/skeletonfolder/skeletonimages'\n",
    "else:\n",
    "    img_directory='/home/sdcastaneda/private/asl_alphabet_train/asl_alphabet_train'\n",
    "    img_directory2='/home/sdcastaneda/private/asl_alphabet_test/asl_alphabet_test'\n",
    "    \n",
    "print(img_directory)\n",
    "###############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc7695",
   "metadata": {},
   "source": [
    "## New Test Set\n",
    "\n",
    "this transforms all of our training and testing datasets to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443f6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8b53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# Create data loaders for the training and validation sets\n",
    "train_datasetskeleton = CustomImageDatasetSkele(\n",
    "    img_dir= img_directory, \n",
    "    skeleton_dir = img_skeleton,\n",
    "    #skeleton_dir ='/home/sdcastaneda/skeleton/skeletonimages',\n",
    "    transform=train_transform,\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor()])\n",
    "\n",
    "# Calculate the sizes for training and validation sets\n",
    "train_size = int(0.9 * len(train_datasetskeleton))\n",
    "val_size = len(train_datasetskeleton) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = random_split(train_datasetskeleton, [train_size, val_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c7e35",
   "metadata": {},
   "source": [
    "## Testing image dataset\n",
    "###Below is a list of the images from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06168f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for displaying the test images here:\n",
    "\n",
    "# Testing\n",
    "#for i in range(0, len(dataset), 30):  # Adjust step to 30 to get one image per class\n",
    "#    image, label = dataset[i]\n",
    "#    image = transforms.ToPILImage()(image)\n",
    "#    plt.imshow(image)\n",
    "#    plt.title(f'Label: {label}')\n",
    "#    plt.axis('off')  # This hides the axis ticks and labels\n",
    "#    plt.show()\n",
    "#    \n",
    "#for i in range(len(dataset)):\n",
    "#    image, label = dataset[i]\n",
    "#    if image.size(1) != 200 or image.size(2) != 200:\n",
    "#        print(f\"Image {i} has a different size: {image.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2a821",
   "metadata": {},
   "source": [
    "## Training Dataset\n",
    "\n",
    "#### Train Dataset has a length of 87,000 images\n",
    "#### These images are 200x200, 29 classes, 26 for A-Z 3 for SPACE, DELETE, and NOTHING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2605e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3382/1674230370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Label: {label}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#for i in range (0,len(train_dataset),3000):\n",
    "#    image, label = train_dataset[i]\n",
    "#    image = transforms.ToPILImage()(image)\n",
    "#    plt.imshow(image)\n",
    "#    plt.title(f'Label: {label}')\n",
    "#    plt.axis('off')  # This hides the axis ticks and labels\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36062224",
   "metadata": {},
   "source": [
    "## Default Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeffcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range (0,len(test_dataset)):\n",
    "#    image, label = test_dataset[i]\n",
    "#    image = transforms.ToPILImage()(image)\n",
    "#    plt.imshow(image)\n",
    "#    plt.title(f'Label: {label}')\n",
    "#    plt.axis('off')  # This hides the axis ticks and labels\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f691ec",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "### we have two train dataset: one with the skeleton images and one without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = DataLoader(test_data, batch_size=64, shuffle=False)  \n",
    "train_dataloaderskeleton = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe70988",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "num_class = 29\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d178cf",
   "metadata": {},
   "source": [
    "# Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3307d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: \n",
    "    - A tuple of (final accuracy, iterations, losses) where:\n",
    "      - final accuracy is the accuracy of the model after the final epoch\n",
    "      - iterations is a list of iteration numbers\n",
    "      - losses is a list of losses corresponding to the iterations\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    iterations = []\n",
    "    losses = []\n",
    "    current_iteration = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(train_dataloaderskeleton):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t + 1, loss.item()))\n",
    "                check_accuracy_part34(final_test, model)\n",
    "                print()\n",
    "\n",
    "            # Store the current iteration and loss for plotting\n",
    "            current_iteration += 1\n",
    "            iterations.append(current_iteration)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    final_accuracy = check_accuracy_part34(final_test, model)\n",
    "    return final_accuracy, iterations, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50be2f",
   "metadata": {},
   "source": [
    "## Classification\n",
    "### This method works well for the default test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8128d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-3\n",
    "num_class = 29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterimBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, batch_norm=False):\n",
    "        super(InterimBlock, self).__init__()\n",
    "        if batch_norm:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(out_channels) \n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.Identity()\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.Identity()\n",
    "        \n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels) if batch_norm else nn.Identity()\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.skip(residual)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, batch_norm=True):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64) if batch_norm else nn.Identity()\n",
    "\n",
    "        self.conv2_x = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            InterimBlock(64, 64, batch_norm=batch_norm),\n",
    "            InterimBlock(64, 64, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv3_x = nn.Sequential(\n",
    "            InterimBlock(64, 128, batch_norm=batch_norm),\n",
    "            InterimBlock(128, 128, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv4_x = nn.Sequential(\n",
    "            InterimBlock(128, 256, batch_norm=batch_norm),\n",
    "            InterimBlock(256, 256, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv5_x = nn.Sequential(\n",
    "            InterimBlock(256, 512, batch_norm=batch_norm),\n",
    "            InterimBlock(512, 512, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3720a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model = ResNet(num_class = num_class,batch_norm= True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca762c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = [64,128,256]\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "for batch_size in batchsize:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True) \n",
    "    test_dataloader2 = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    model = ResNet(num_class = num_class,batch_norm= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "    \n",
    "    final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=5)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iterations, losses, label='Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss vs. Iteration - {batch_size}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = [1e-2,1e-3,1e-4]\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "for learning_rate in learningrate:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True) ## Normal Kaggle test dataset (28 images)\n",
    "    test_dataloader2 = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "#####################################If needing to change NN#####    \n",
    "    model = ResNet(num_class = num_class,batch_norm= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                         momentum=0.9, nesterov=True)\n",
    "\n",
    "###############################################################################\n",
    "    final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iterations, losses, label='Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss vs. Iteration - {batch_size}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81a9d2",
   "metadata": {},
   "source": [
    "# Varying Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(\n",
    "    img_dir= img_directory, \n",
    "    transform=train_transform, \n",
    "    mode='train'\n",
    ")\n",
    "# Calculate the sizes for training and validation sets\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = random_split(train_dataset, [train_size, val_size])\n",
    "train_dataloaderskeleton = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "final_test = DataLoader(test_data, batch_size=64, shuffle=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterimBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, batch_norm=False):\n",
    "        super(InterimBlock, self).__init__()\n",
    "        if batch_norm:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(out_channels) \n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.Identity()\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.Identity()\n",
    "        \n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels) if batch_norm else nn.Identity()\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.skip(residual)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, batch_norm=True):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64) if batch_norm else nn.Identity()\n",
    "\n",
    "        self.conv2_x = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            InterimBlock(64, 64, batch_norm=batch_norm),\n",
    "            InterimBlock(64, 64, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv3_x = nn.Sequential(\n",
    "            InterimBlock(64, 128, batch_norm=batch_norm),\n",
    "            InterimBlock(128, 128, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv4_x = nn.Sequential(\n",
    "            InterimBlock(128, 256, batch_norm=batch_norm),\n",
    "            InterimBlock(256, 256, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.conv5_x = nn.Sequential(\n",
    "            InterimBlock(256, 512, batch_norm=batch_norm),\n",
    "            InterimBlock(512, 512, batch_norm=batch_norm)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8294d28",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = ResNet(num_class = num_class,batch_norm= True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = [64,128,256]\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "for batch_size in batchsize:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True) \n",
    "    test_dataloader2 = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    model = ResNet(num_class = num_class,batch_norm= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "    \n",
    "    final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=5)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iterations, losses, label='Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss vs. Iteration - {batch_size}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ec292",
   "metadata": {},
   "source": [
    "# Varying Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = [1e-2,1e-3,1e-4]\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "for learning_rate in learningrate:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True) ## Normal Kaggle test dataset (28 images)\n",
    "    test_dataloader2 = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "#####################################If needing to change NN#####    \n",
    "    model = ResNet(num_class = num_class,batch_norm= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                         momentum=0.9, nesterov=True)\n",
    "\n",
    "###############################################################################\n",
    "    final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iterations, losses, label='Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss vs. Iteration - {batch_size}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428fdfa",
   "metadata": {},
   "source": [
    "# Experimenting with Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size = 64\n",
    "best_learning_rate = 1e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "for learning_rate in learningrate:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True) ## Normal Kaggle test dataset (28 images)\n",
    "    test_dataloader2 = DataLoader(dataset, batch_size, shuffle=True)\n",
    "##If needing to change NN #########################   \n",
    "    model = ResNet(num_class = num_class,batch_norm= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "    \n",
    "##############################################################\n",
    "    final_accuracy, iterations, losses = train_part34(model, optimizer, epochs=1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iterations, losses, label='Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss vs. Iteration - {batch_size}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0710a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ec6cb2",
   "metadata": {},
   "source": [
    "# Analysis of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27131bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
